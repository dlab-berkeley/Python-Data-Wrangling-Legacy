{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce1408f",
   "metadata": {},
   "source": [
    "# `pandas`\n",
    "\n",
    "This workshop's goal&mdash;which is facilitated by this Jupyter notebook&mdash;is to give attendees the confidence to use `pandas` in their research projects. Basic familiarity with Python *is* assumed.\n",
    "\n",
    "`pandas` is designed to make it easier to work with structured data. Most of the analyses you might perform will likely involve using tabular data, e.g., from .csv files or relational databases (e.g., SQL). The `DataFrame` object in `pandas` is \"a two-dimensional tabular, column-oriented data structure with both row and column labels.\"\n",
    "\n",
    "If you're curious:\n",
    "\n",
    ">The `pandas` name itself is derived from *panel data*, an econometrics term for multidimensional structured data sets, and *Python data analysis* itself. After getting introduced, you can consult the full [`pandas` documentation](http://pandas.pydata.org/pandas-docs/stable/).\n",
    "\n",
    "To motivate this workshop, we'll work with example data and go through the various steps you might need to prepare data for analysis. You'll (hopefully) realize that doing this type of work is much more difficult using Python's built-in data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e484854",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "1 - [The DataFrame](#section1)<br>\n",
    "\n",
    "2 - [Rename, Index, and Slice](#section2)<br>\n",
    "\n",
    "3 - [Data Analysis](#section3)<br>\n",
    "\n",
    "4 - [Data Manipulation](#section4)<br>\n",
    "\n",
    "5 - [Groupby](#section5)<br>\n",
    "\n",
    "6 - [Concatenation & Joins](#section6)<br>\n",
    "\n",
    "7- [Plotting](#section7)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa8cb6",
   "metadata": {},
   "source": [
    "## 1. The DataFrame <a id=\"section1\"/>\n",
    "The data used in these examples is available in the following [GitHub repository](https://github.com/dlab-berkeley/introduction-to-pandas). If you've [cloned that repo](https://www.atlassian.com/git/tutorials/setting-up-a-repository/git-clone), which is the recommended approach, you'll have everything you need to run this notebook. Otherwise, you can download the data file(s) from the above link. (Note: this notebook assumes that the data files are in a directory named `data/` found within your current working directory.)\n",
    "\n",
    "We plan on working with a variety of datasets ranging from unemployment statistics to happiness measures to pokemon attributes and more.\n",
    "\n",
    "Let's begin by importing `pandas` using the conventional abbreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65398cda",
   "metadata": {},
   "source": [
    "The `read_csv()` function in `pandas` allows us to easily import our data. By default, it assumes the data is comma-delimited. However, you can specify the delimiter used in your data (e.g., tab, semicolon, pipe, etc.). There are several parameters that you can specify. See the documentation [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). `read_csv()` returns a `DataFrame`.\n",
    "\n",
    "Notice that we call `read_csv()` using the `pd` abbreviation from the import statement above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dd725",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.read_csv('data/country_total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c822b80",
   "metadata": {},
   "source": [
    "Great! You've created a `pandas` `DataFrame`. We can look at our data by using the `.head()` method. By default, this shows the header (column names) and the first five rows. Passing an integer, $n$, to `.head()` returns that number of rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbfbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc13bb62",
   "metadata": {},
   "source": [
    "DataFrames all have a method called `tail` that takes an integer as an argument and returns a new DataFrame. Before using `tail`, can you guess at what it does? Try using `tail`; was your guess correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbce6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3c1f8",
   "metadata": {},
   "source": [
    "To find the number of rows, you can use the `shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fdad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53308243",
   "metadata": {},
   "source": [
    "There are 20,796 rows and 5 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6926237",
   "metadata": {},
   "source": [
    "The `.info()` method is an incredibly useful diagnostic tool for when you're getting to know a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c54840",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d9a41",
   "metadata": {},
   "source": [
    "`.info()` tells us:\n",
    "- Number of rows and columns\n",
    "- The data type of each column and the tally of each datatype.\n",
    "- The number of non-null values. If those numbers are less than the number of total rows then that column has null values.\n",
    "- The size of the dataframe in kilobytes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62398327",
   "metadata": {},
   "source": [
    "The attributes of `.columns` and `.dtypes` return the column names and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column names\n",
    "unemployment.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0236c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data types\n",
    "unemployment.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6770369",
   "metadata": {},
   "source": [
    "`read_csv` is [a very flexible method](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.read_csv.html); it also allows us to import data using a URL as the file path. \n",
    "\n",
    "A csv file with data on world countries and their abbreviations is located at [https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv](https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv) (saved as a string variable `countries_url` below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv'\n",
    ")\n",
    "countries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1248afb",
   "metadata": {},
   "source": [
    "## 2. Rename, Indexing, Dropping, and Slicing <a id=\"section2\"/>\n",
    "Back to the entire unemployment data set. You may have noticed that the `month` column also includes the year. Let's go ahead and rename it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f21cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.rename(columns={'month' : 'year_month'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ff51d",
   "metadata": {},
   "source": [
    "The `.rename()` method allows you to modify index labels and/or column names. As you can see, we passed a `dict` to the `columns` parameter, with the original name as the key and the new name as the value. Importantly, we also set the `inplace` parameter to `True`, which modifies the *actual* `DataFrame`, not a copy of it.\n",
    "\n",
    "To select a single column we can either use bracket (`[]`) or dot notation (referred to as *attribute access*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0799fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['year_month'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.year_month.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7edf89",
   "metadata": {},
   "source": [
    "It is preferrable to use the bracket notation as a column name might inadvertently have the same name as a `DataFrame` (or `Series`) method. In addition, only bracket notation can be used to create a new column. If you try and use attribute access to create a new column, you'll create a new attribute, *not* a new column.\n",
    "\n",
    "When selecting a single column, we have a `pandas` `Series` object, which is a single vector of data (e.g., a NumPy array) with \"an associated array of data labels, called its *index*.\" A `DataFrame` also has an index. In our example, the indices are an array of sequential integers, which is the default. You can find them in the left-most position, without a column label.\n",
    "\n",
    "Indices need not be a sequence of integers. They can, for example, be dates or strings. Note that indices do *not* need to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101440cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a04ffaa3",
   "metadata": {},
   "source": [
    "We can select multiple columns by effectively slicing the dataframe with a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment[[\"year_month\", \"unemployment\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fafa051",
   "metadata": {},
   "source": [
    "Deleting columns is done with the `.drop()` method. **This method is used for the index and columns** therefore we must specify `axis = 1` to tell pandas to drop a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92436234",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.drop(\"unemployment\", axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0767c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple columns\n",
    "unemployment.drop([\"unemployment\", \"seasonality\"], axis = 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2baf75",
   "metadata": {},
   "source": [
    "This change isn't permanent because `inplace=False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanently drop a column\n",
    "#unemployment.drop(\"unemployment\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07655ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e4646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "659cc047",
   "metadata": {},
   "source": [
    "Look at a few more useful ways to index data&mdash;that is, select rows.\n",
    "\n",
    "`.loc` primarily works with string labels. It accepts a single label, a list (or array) of labels, or a slice of labels (e.g., `'a' : 'f'`).\n",
    "\n",
    "Let's create a `DataFrame` to see how this works. (This is based on an [example](https://github.com/fonnesbeck/scipy2015_tutorial/blob/master/notebooks/1.%20Data%20Preparation.ipynb) from Chris Fonnesbeck's [Computational Statistics II Tutorial](https://github.com/fonnesbeck/scipy2015_tutorial).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria = pd.DataFrame({'bacteria_counts' : [632, 1638, 569, 115],\n",
    "                         'other_feature' : [438, 833, 234, 298]},\n",
    "                         index=['Firmicutes', 'Proteobacteria', 'Actinobacteria', 'Bacteroidetes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1849e3",
   "metadata": {},
   "source": [
    "Notice that we pass in a `dict`, where the keys correspond to column names and the values to the data. In this example, we've also set the indices&mdash;strings in this case&mdash;to be the taxon of each bacterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305ae85",
   "metadata": {},
   "source": [
    "Now, if we're interested in the values (row) associated with \"Actinobacteria,\" we can use `.loc` and the index name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria.loc['Actinobacteria']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d8393",
   "metadata": {},
   "source": [
    "This returns the column values for the specified row. Interestingly, we could have also used \"positional indexing,\" even though the indices are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea202eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria[2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa26dc",
   "metadata": {},
   "source": [
    "The difference is that the former returns a `Series` because we selected a single lable, while the latter returns a `DataFrame` because we selected a range of positions.\n",
    "\n",
    "Let's return to our unemployment data. Another indexing option, `.iloc`, primarily works with integer positions. To select specific rows, we can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43758389",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.iloc[[1, 5, 6, 9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d685b34",
   "metadata": {},
   "source": [
    "We can select a range of rows and specify the step value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.iloc[25:50:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce6ec38",
   "metadata": {},
   "source": [
    "(Note: As is typical in Python, the end position is not included. Therefore, we don't see the row associated with the index 50.)\n",
    "\n",
    "Indexing is important. You'll use it a lot. Below, we'll show how to index based on data values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba08d2",
   "metadata": {},
   "source": [
    "The \"other_feature\" column in our `bacteria` table isn't very descriptive. Suppose we know that \"other_feature\" refers to a second set of bacteria count observations. Use the `rename` method to give \"other_feature\" a more descriptive name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename \"other_feature\" in bacteria\n",
    "bacteria.rename(columns={'other_feature':'second_count'}, inplace=True)\n",
    "bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2871215c",
   "metadata": {},
   "source": [
    "### Challenge 1A: Indexing to get a specific value\n",
    "\n",
    "Both `loc` and `iloc` can be used to select a particular value if they are given two arguments. The first argument is the name (when using `loc`) or index number (when using `iloc`) of the *row* you want, while the second argument is the name or index number of the *column* you want.\n",
    "\n",
    "Using `loc`, select \"Bacteroidetes\" and \"bacteria_counts\" to get the count of Bacteroidetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4f2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d848148c",
   "metadata": {},
   "source": [
    "How could you do the same task using `iloc`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2a00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e22af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b2d9406",
   "metadata": {},
   "source": [
    "### Challenge 1B: Indexing multiple rows and columns\n",
    "\n",
    "Both `loc` and `iloc` can be used to select subsets of columns *and* rows at the same time if they are given lists (and/or slices, for `iloc`] as their two arguments. \n",
    "\n",
    "Using `iloc` on the `unemployment` DataFrame, get:\n",
    "* every row starting at row 4 and ending at row 7\n",
    "* the 0th, 2nd, and 3rd columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665eebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c636ba6",
   "metadata": {},
   "source": [
    "Repeat same task but with `loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c72db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba1bbbdc",
   "metadata": {},
   "source": [
    "Uh-oh, those are different! Why? Because using slices in `.loc` treats the end position in the slice inclusively, while slicing with `.iloc` (and on the dataframe itself!) treats the end position in the slice exclusively (as Python lists and `numpy` does).\n",
    "\n",
    "So, we need to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673e9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb425d4a",
   "metadata": {},
   "source": [
    "### Boolean Indexing or Conditional Filtering \n",
    "Suppose we wanted to construct a dataframe for a specific country and above a certain unemployment rate threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89917c",
   "metadata": {},
   "source": [
    "**Task**: Return a dataframe where the unemployment rate is greater than 9.0 for the country of France?\n",
    "\n",
    "- Step 1: Grab rows belonging to France\n",
    "- Step 2: Grab rows where unemployment rate is greater than 9.0%\n",
    "- Step 3: Use the two conditions to filter or index the `unemployment` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select unemployment rate and country columns\n",
    "unemployment_rate = unemployment.unemployment_rate\n",
    "country = unemployment.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a boolean mask for un rate\n",
    "unemployment_rate>9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106e7df",
   "metadata": {},
   "source": [
    "The mask produces an array of boolean values equal to the length of the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20def65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create boolean mask for country\n",
    "country == 'fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56218f",
   "metadata": {},
   "source": [
    "First let's filter the `unemployment_rate` series using our threshold of 9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We pass in the boolean mask like we're slicing the dataframe\n",
    "unemployment[unemployment_rate>9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49756d02",
   "metadata": {},
   "source": [
    "This returns a dataframe where value under unemployment rate is greater than 9.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country version using france\n",
    "unemployment[country=='fr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253deed",
   "metadata": {},
   "source": [
    "Now let's combine the two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap both boolean masks in parentheses and use an & sign to make their conditions exclusive\n",
    "unemployment[(unemployment.unemployment_rate>9.0) & (unemployment.country == 'fr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91f026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfad257a",
   "metadata": {},
   "source": [
    "### Challenge 2: Slicing Census Data\n",
    "\n",
    "Using the pre-loaded the census dataset featuring a collection of US counties and their socio-economic attribues, answer the following questions \n",
    "\n",
    "- Create a subset dataframe using loc containing the following columns: State, County, WorkAtHome, MeanCommute\n",
    "- Create a dataframe of counties exclusively from each of the following counties: Kansas, Maryland, Oregon\n",
    "- How many counties in California have a total population greater than 250000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv(\"data/census_data.csv\")\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf24b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24fc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f6e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3b727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbeada1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be3be2b3",
   "metadata": {},
   "source": [
    "## 3. Data Analysis <a id=\"section3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f284b05",
   "metadata": {},
   "source": [
    "Pandas is great for conducting exploratory data analysis. We need to find a the mean of a column or count the proportions of a categorical variable's items, pandas is your go-to tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7029d",
   "metadata": {},
   "source": [
    "Let's introduce a new dataset: movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c760b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(path)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abdca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70224bf8",
   "metadata": {},
   "source": [
    "Before we move ahead let's fix the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d632b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the str operator to lower case the column names and replace the spaces with an underscore\n",
    "movies.columns = movies.columns.str.lower().str.replace(\" \", \"_\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34ad23",
   "metadata": {},
   "source": [
    "To generate a set of summary stats call the `.describe()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf34c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfd4ee",
   "metadata": {},
   "source": [
    "You may have noticed that the \"count\" is lower for certain columns. This is because the summary statistics are based on *non-missing* values and count reflects that.\n",
    "\n",
    "The values depend on what it's called on. If the `DataFrame` includes both numeric and object (e.g., strings) `dtype`s, it will default to summarizing the numeric data. If `describe` is called on strings, for example, it will return the count, number of unique values, and the most frequent value along with its count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe works on series too\n",
    "movies.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda28107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean, median\n",
    "movies.rating.mean(), movies.rating.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2368732b",
   "metadata": {},
   "source": [
    "What if you're interested in knowing what are the best or worst rated movies?\n",
    "\n",
    "The `nlargest` and `nsmallest` methods can be of assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the 5 best films\n",
    "movies.rating.nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b47226",
   "metadata": {},
   "source": [
    "The `n` parameter's default is set to 5. \n",
    "\n",
    "However we only see the `rating` values and not the movie titles associated with them. \n",
    "\n",
    "\n",
    "Using `nlargest` with the `columns` parameter set to `ratigin` on `movies` to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca835d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe version of .nlargest()\n",
    "movies.nlargest(n = 5, columns=\"rating\")[[\"title\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92aba7c",
   "metadata": {},
   "source": [
    "Conversely we can use `nsmallest` to output the worst films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe version of .nlargest()\n",
    "movies.nsmallest(n = 5, columns=\"rating\")[[\"title\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea9a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bd5f971",
   "metadata": {},
   "source": [
    "The `movies` dataset has some interesting categorical data that we should examine as well.\n",
    "\n",
    "Let's find out what the various genres are at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_type = movies.genre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d6b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the unique pokemon types\n",
    "g_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e673966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of uniques\n",
    "g_type.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d095ee",
   "metadata": {},
   "source": [
    "The `value_counts` method can tell us how the frequencies of each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf94737",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ccc33",
   "metadata": {},
   "source": [
    "What if we're interested in proportions? Set the `normalize` parameter to `True` in the `value_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_type.value_counts(normalize = True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be5cec",
   "metadata": {},
   "source": [
    "A common task for exploratory data analysis is looking at the correlations in your dataset. I'm interested to see if there a number of similar attributes in the dataset. \n",
    "\n",
    "We can use the `corr` method to return a table of all the correlations between pairs of numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ad935",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are all the correlations for the revenue_millions column?\n",
    "movies.corr()[\"revenue_millions\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15370d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whats the correlation between rating and revenue_millions?\n",
    "movies.corr().loc[\"rating\", \"revenue_millions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfa139",
   "metadata": {},
   "source": [
    "### Challenge 3: Analyzing Census Data\n",
    "\n",
    "Using the census data we imported earlier, complete the following tasks.\n",
    "- How many counties does each state have?\n",
    "- What are the average and standard deviation for county population\n",
    "- What columns have the highest correlations with poverty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ce7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cb2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de0aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e2399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f973c21a",
   "metadata": {},
   "source": [
    "## 4. Manipulating Data <a id=\"section4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e0b81",
   "metadata": {},
   "source": [
    "The vast majority of work done with data consists of cleaning, transforming, and other forms reshaping it to your needs. More often than not data you receive will have missing values (nulls), come in an unfriendly format, and have misspelled labels.\n",
    "\n",
    "Data preparation is a necessary pre-requisite to tasks such as data visualization and machine learning. A machine learning model can't process missing or non-numerical data, so it's incumbent on you to feed prep your data for the model.\n",
    "\n",
    "Luckily for us, pandas has provides relatively easy and intuitive tools which we can use to reconfigure our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60598e83",
   "metadata": {},
   "source": [
    "#### Sorting\n",
    "\n",
    "We touched on the idea of ordering data earlier with `nlargest` and `nsmallest` but sometimes we may need to turn to `sort_values` for permantently ordering data or sorting by multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accac559",
   "metadata": {},
   "source": [
    "The `ascending` parameter defaults to `True` which means it orders data from least to greatest. Set it to `False` to to reverse that order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series version\n",
    "movies.production_budget.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5692c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe version\n",
    "movies.sort_values(by = \"production_budget\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a67cf",
   "metadata": {},
   "source": [
    "How can we make this sorting permanent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a564fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set inplace equal to True\n",
    "movies.sort_values(by = \"rating\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcdd4f",
   "metadata": {},
   "source": [
    "Remember that whenever you use `inplace=True` you won't see an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View sorted dataframe\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7b8aa",
   "metadata": {},
   "source": [
    "The index can also be sorted, which we can do to actually undo the previous action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View change\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a8f71",
   "metadata": {},
   "source": [
    "Now let's sort by multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize column list\n",
    "cols = [\"year\", \"runtime_minutes\"]\n",
    "#Sort data from least to greatest first by year and then by runtime\n",
    "movies.sort_values(by = cols, ascending=True)[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f0033",
   "metadata": {},
   "source": [
    "The above `DataFrame` sorts primarily with `year` and in the case of ties then defers to `runtime_minutes` as its sorting criteria.\n",
    "\n",
    "We can also feed in a list of boolean values to `ascending` if for instance we'd like to use different orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3923d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort data from greatest to least by year and then least to greatest by runtime\n",
    "movies.sort_values(by = cols, ascending=[False, True])[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb6dc3",
   "metadata": {},
   "source": [
    "### Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497f0ca",
   "metadata": {},
   "source": [
    "Pandas marks missing data or null data as \"NaN\" which stands for \"Not a Number.\" To find these null values we use the `.isnull()` method. This function returns a corresponding boolean value for each value in a `Series` or `DataFrame`.\n",
    "\n",
    "In Python `True` is equivalent to 1 and `False` is equivalent to 0. Thus we can sum up all the values in the boolean mask with `.sum()` to give us a count for the *total* number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14518c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.genre3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce90c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return isnull boolean mask\n",
    "movies.genre3.isnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return number of missing values in genre3\n",
    "movies.genre3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of missing values for every column\n",
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc78095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using .mean() effectively tells us the percent of null values in each column\n",
    "movies.isnull().mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ab72d",
   "metadata": {},
   "source": [
    "Since `.isnull()` outputs a boolean mask, we can use that array to conditionally filter the `Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.genre3.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b936db",
   "metadata": {},
   "source": [
    "The output above returns a `DataFrame` of every row every where `genre3` has a NaN. If we want to filter out NaNs under that column place `~` at the start of the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[~movies.genre3.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb4325",
   "metadata": {},
   "source": [
    "A more formal way to get rid of nulls is to use `.dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed205054",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.genre3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e757b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame version\n",
    "movies.dropna(subset=[\"genre3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba60003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "033086b2",
   "metadata": {},
   "source": [
    "**If we wanted to permanently drop nulls what do you guess would be the way to do so?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac2b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068067b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd59dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a679aed1",
   "metadata": {},
   "source": [
    "If you said `inplace=True` then you're right!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies.dropna(subset=['genre3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f183b9e",
   "metadata": {},
   "source": [
    "Now `movies` has no NaNs under the `genre3` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4550ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0643c33e",
   "metadata": {},
   "source": [
    "Sometimes we may not want to get rid of nulls but rather replace them with our own preferred value. This is what's referred to as imputation. It's a technique typically used in machine learning to \"save\" data that missing data by replacing NaNs with an estimated value â€” a mean typically used.\n",
    "\n",
    "`.fillna()` replaces nulls with an input value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the missing metascore values with its mean\n",
    "meta_mean = movies.metascore.mean()\n",
    "movies.metascore.fillna(meta_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ba2a5",
   "metadata": {},
   "source": [
    "How can we go about replacing the missing `genre2` and `genre3` values with a string that says \"no_genre\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = \"no_genre\"\n",
    "movies.genre2.fillna(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588bd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.genre3.fillna(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563ed77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a365c81",
   "metadata": {},
   "source": [
    "### Changing Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ec6a4",
   "metadata": {},
   "source": [
    "There are instances where data is not encoded in the right way. For instance, numerical data such as dollars and percents presented as strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d941fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create fake dataframe \n",
    "percent_sales = pd.DataFrame({\"percents\":[\"30.2\", \"97.5\", \"61.0\"],\n",
    "                               \"revenue\": [\"$3438\", \"$2393\", \"$1892\"]})\n",
    "percent_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb60846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View data types\n",
    "percent_sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0eda7",
   "metadata": {},
   "source": [
    "Changing the type of `percents` can be done with `.astype()` and passing in \"float\" as the desired data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc659dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_sales.percents.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a0b38",
   "metadata": {},
   "source": [
    "`.astype()` does not has `inplace=True` so to make it permanent, we overwrite the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85257841",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_sales[\"percents\"] = percent_sales.percents.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a6a83",
   "metadata": {},
   "source": [
    "Now revenue's turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_sales.revenue.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a907136",
   "metadata": {},
   "source": [
    "We get an error! \n",
    "\n",
    "That's because of the pesky $ signs. We can only convert string representations of numbers to floats, not non-numerical characters.\n",
    "\n",
    "This necessitates removing the $ sign which introduces us to `.str` which is essentially a method allows us to use typical string methods such as `.lower()` and `.title()` on `Series`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1ad66",
   "metadata": {},
   "source": [
    "We first call `.str` then `.replace()` which we use to get rid of the $ signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_sales.revenue.str.replace(\"$\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c75991",
   "metadata": {},
   "source": [
    "Now we can convert \"revenue\" to a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce38a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_sales.revenue.str.replace(\"$\", \"\").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c3230a",
   "metadata": {},
   "source": [
    "Go back to the unemployment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ff490",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed68d02",
   "metadata": {},
   "source": [
    "We need to **split `year_month` into two separate columns.** Above, we saw that this column is type (technically, `dtype`) `float64`. We can extract the year using with `.astype()` method. This allows for type casting&mdash;basically converting from one type to another. We'll then subtract this value from `year_month`&mdash;to get the decimal portion of the value&mdash;and multiply the result by 100 and convert to `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['year'] = unemployment['year_month'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc9057",
   "metadata": {},
   "source": [
    "In this case, we're casting the floating point values to integers. In Python, this [truncates the decimals](https://docs.python.org/2/library/stdtypes.html#numeric-types-int-float-long-complex).\n",
    "\n",
    "Finally, let's create our **month** variable as described above. (Because of the truncating that occurs when casting to `int`, we first round the values to the nearest whole number.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479221f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['month'] = ((unemployment['year_month'] - unemployment['year']) * 100).round(0).astype(int)\n",
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf811efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b5bc46f",
   "metadata": {},
   "source": [
    "### Inter Column operations\n",
    "\n",
    "The great thing about data is that you create more data from what it's in front of you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef81d72",
   "metadata": {},
   "source": [
    "This dataset is missing some important information such as the profit line of each film. The good news is we can derive those numbers from what we have in front of us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8057f",
   "metadata": {},
   "source": [
    "Let's derive the profit figures for our set of films. First thing we need to do is fix the revenue column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c565980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple revenue_millions by a million\n",
    "movies[\"revenue_millions\"] *= 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfe794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column in movies called profit by subtracting production_budget from revenue_millions\n",
    "movies[\"profit\"] = movies[\"revenue_millions\"] - movies[\"production_budget\"]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8b1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ab7777c",
   "metadata": {},
   "source": [
    "### Challenge 4\n",
    "\n",
    "Time for some pokemon data analysis. Using the `pokemon` dataset complete the following tasks\n",
    "\n",
    "- What are the 10 pokemon with the highest and lowest hp values? Show just the name\n",
    "- Which 3 columns have the most null values?\n",
    "- Create a new column that represents `height_m` in inches. Reminder: There 39.37 inches in a meter.\n",
    "- What are is the average speed for pokemon that are marked as 1 and 0 under `is_legendary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793028af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon = pd.read_csv(\"data/pokemon.csv\")\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9f16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66772150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec9dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86219e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed040fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043ef54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "866a5009",
   "metadata": {},
   "source": [
    "## 5. Groupby  <a id=\"section5\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad0a49",
   "metadata": {},
   "source": [
    "\n",
    "What if we'd like to apply certain operations based on a categorization of data? For instance deriving the average rating value for each film genre?\n",
    "\n",
    "In other words we need to *group* the films *by* their genre designation.\n",
    "\n",
    "Which we can do with the `.groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average rating by genre.\n",
    "movies.groupby(\"genre1\").rating.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c10e0",
   "metadata": {},
   "source": [
    "Let's explain what just happened. We start with our `DataFrame`. We tell `pandas` that we want to group the data by generation;that's what goes in the parentheses. Next, we need to tell it what column we'd like to perform the `.mean()` operation on. In this case, it's the `rating` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat but with .describe()\n",
    "movies.groupby(\"genre1\").rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25a1ab",
   "metadata": {},
   "source": [
    "We can also groupby multiple columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4849f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize list of columns to group by with\n",
    "cols = [\"genre1\", \"year\"]\n",
    "movies.groupby(cols).rating.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use as_index = False to return a dataframe\n",
    "movies.groupby(cols, as_index=False).rating.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb65b0",
   "metadata": {},
   "source": [
    "### Challenge 5:\n",
    "\n",
    "- Create a series that order generations of pokemon by their average attack rating from greatest to least\n",
    "- Replace the NaNs in `type2` with \"no_type\" and then group by `type1` and `type2` and derive the median `speed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bda1c",
   "metadata": {},
   "source": [
    "## 6. Merging and Concatenation <a id=\"section6\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639f4e8",
   "metadata": {},
   "source": [
    "How can we connect two different dataset along their columns or rows? Similar to how we concatenate strings, we can concatenate dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09a06f",
   "metadata": {},
   "source": [
    "Load in the two different datasets from the [world happiness report](https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021?select=world-happiness-report.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness2010 = pd.read_csv(\"data/word_happiness_report_2010.csv\")\n",
    "happiness2009 = pd.read_csv(\"data/word_happiness_report_2009.csv\")\n",
    "happiness2009.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num rows\n",
    "happiness2009.shape[0], happiness2010.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771ba95",
   "metadata": {},
   "source": [
    "Both dataframes are structured the same and represent the same information but for two different years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc846ae",
   "metadata": {},
   "source": [
    "If we wanted to conduct an operation that looks a change in a metric from one year to the next for a country we first need to combine or concatenate the two dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965db9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First assemble the dataframes in a list\n",
    "df_list = [happiness2009, happiness2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b6622",
   "metadata": {},
   "source": [
    "`pd.concat()` is the method for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d309e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass in df_list to the concatenation funcion and set axis = 0\n",
    "happiness = pd.concat(df_list, axis = 0)\n",
    "happiness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282bbac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the index to get rid of duplicates\n",
    "happiness.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num rows\n",
    "happiness.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed106fa8",
   "metadata": {},
   "source": [
    "The `axis` method is a crucial for this function because we are telling pandas to concatenate the dataframes vertically instead of horizontally. We do this because they have the same columns and thus should combined along that axis.\n",
    "\n",
    "\n",
    "Setting `axis` to 1 would attach the dataframes side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f5a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8d8cb68",
   "metadata": {},
   "source": [
    "Now let's bring back the unemployment data and connect it with the happiness data.\n",
    "\n",
    "This time when we combine the data, we are going to be merging them together, aka joining them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78547875",
   "metadata": {},
   "source": [
    "Our two datasets will be the 2010 happiness data and a version of the unemployment data that pulls the seasonally adjusted median unemployment rate for the year 2010 for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fce913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2010 seasonally adjusted subset\n",
    "unemployment2010_sa = unemployment[(unemployment.seasonality == 'sa') & (unemployment.year == 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d81800",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment2010_sa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by country derive median\n",
    "median_unemployment = unemployment2010_sa.groupby(\"country\", as_index=False).unemployment_rate.median()\n",
    "median_unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68fac9f",
   "metadata": {},
   "source": [
    "`pandas` includes an easy-to-use `.merge()` function. Let's use it to **merge  `median_unemployment` and `happiness2010` using country codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(happiness2010,median_unemployment, left_on=\"country_code_name\", right_on=\"country\")\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738a2d0",
   "metadata": {},
   "source": [
    "Merging is often more complex than this example. If you want to merge on multiple columns, you can pass a list of column names to the `on` parameter.\n",
    "\n",
    "```\n",
    "pd.merge(first, second, on=['name', 'id'])\n",
    "```\n",
    "\n",
    "The `how` parameter is set to \"inner\" which means that the output will only include values that appear in both of the columns the dataframes are being joined on.\n",
    "\n",
    "For more information on merging, check the [documentation](http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a02461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num rows can be a good indicator of how well our join did.\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d137e1de",
   "metadata": {},
   "source": [
    "Is there a relationship between unemployment rate and other variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe60719",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.corr()[\"unemployment_rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3a618",
   "metadata": {},
   "source": [
    "We can save this dataset with the `.to_csv()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d770c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged.to_csv(\"happiness_unemployment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a9e2c",
   "metadata": {},
   "source": [
    "## 7. Plotting With Pandas  <a id=\"section7\"/>\n",
    "\n",
    "The best way to get a sense of this data is to **plot it.** Next, we'll start to look at some basic plotting with `pandas`. Before we begin, let's sort the data by country and date. This is good practice and is especially important when using `pandas`'s `.plot()` method because the x-axis values are based on the indices. When we sort, the index values remain unchanged. Thus, we need to reset them. The `drop` parameter tells `pandas` to construct a `DataFrame` *without* adding a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.sort_values(['country', 'year_month'], inplace=True)\n",
    "unemployment.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77356f84",
   "metadata": {},
   "source": [
    "Let's take a look at Spain's unemployment rate (only because it was the highest) across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e575126",
   "metadata": {},
   "outputs": [],
   "source": [
    "spain = unemployment[(unemployment['country'] == 'es') &\n",
    "                     (unemployment['seasonality'] == 'sa')]\n",
    "\n",
    "spain[\"country\"] = \"Spain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aead43",
   "metadata": {},
   "outputs": [],
   "source": [
    "spain['unemployment_rate'].plot(figsize=(10, 8), color='#348ABD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d160f",
   "metadata": {},
   "source": [
    "Note that the values along the x-axis represent the indices associated with Spain in the sorted `unemployment` `DataFrame`. Wouldn't it be nice if, instead, we could **show the time period** associated with the various unemployment rates for Spain? It might also be interesting to **compare** Spain's unemployment rate with its neighbor to the west, Portugal.\n",
    "\n",
    "Let's first create a `DataFrame` that contains the unemployment data for both countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00db471",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = unemployment[(unemployment['country'].isin(['pt', 'es'])) &\n",
    "                  (unemployment['seasonality'] == 'sa')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0162ba7",
   "metadata": {},
   "source": [
    "For a quick tasks that involving replacing data values, use a dictionary where the old values are the keys and the new ones are the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dictionary which we use to turn pt -> Portugal and es -> Spain\n",
    "country_map = {\"pt\":\"Portugal\", \"es\":\"Spain\"}\n",
    "\n",
    "ps[\"country\"] = ps[\"country\"].map(country_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6465a29",
   "metadata": {},
   "source": [
    "Next, we'll **generate time series data** by converting our years and months into `datetime` objects. `pandas` provides a `to_datetime()` function that makes this relatively simple. It converts an argument&mdash;a single value or an array of values&mdash;to `datetime`. (Note that the return value [depends on the input](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html).) If we were interested in March 23, 1868, for example, we could do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('1868/3/23')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c755e",
   "metadata": {},
   "source": [
    "The argument doesn't necessarily have to be specified in the `yyyy/mm/dd` format. You could list it as `mm/dd/yyyy`, but it's a good idea to be explicit. As a result, we pass in a valid string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('3/23/1868', format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5d9b7",
   "metadata": {},
   "source": [
    "Let's create the `datetime` object and add it to the `DataFrame` as a column named `date`. For this, we'll use the `DataFrame.insert()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.insert(loc=0, column='date',\n",
    "          value=pd.to_datetime(ps['year'].astype(str) + '/' + ps['month'].astype(str) + '/1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e351de3",
   "metadata": {},
   "source": [
    "Finally, let's only keep certain columns, rename them, and reshape the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627aba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ps[['date', 'country', 'unemployment_rate']]\n",
    "ps.columns = ['Time Period', 'Country', 'Unemployment Rate']\n",
    "ps = ps.pivot(index='Time Period', columns='Country', values='Unemployment Rate')\n",
    "ps.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd86961",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494a536",
   "metadata": {},
   "source": [
    "Notice the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.plot(figsize=(10, 8), title='Unemployment Rate\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
