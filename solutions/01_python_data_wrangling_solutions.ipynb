{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Wrangling with `pandas` Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust some settings in matplotlib\n",
    "mpl.rc('savefig', dpi=200)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['xtick.minor.size'] = 0\n",
    "plt.rcParams['ytick.minor.size'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.read_csv('../data/country_total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 1: Import Data From A URL\n",
    "\n",
    "Above, we imported the unemployment data using the `read_csv` function and a relative file path. `read_csv` is [a very flexible method](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.read_csv.html); it also allows us to import data using a URL as the file path. \n",
    "\n",
    "A csv file with data on world countries and their abbreviations is located at the URL:\n",
    "\n",
    "[https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv](https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv)\n",
    "\n",
    "We've saved this exact URL as a string variable, `countries_url`, below.\n",
    "\n",
    "Using `read_csv`, import the country data and save it to the variable `countries`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_url = 'https://raw.githubusercontent.com/dlab-berkeley/Python-Data-Wrangling/main/data/countries.csv'\n",
    "countries = pd.read_csv(countries_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: The `tail` method\n",
    "\n",
    "DataFrames all have a method called `tail` that takes an integer as an argument and returns a new DataFrame. Before using `tail`, can you guess at what it does? Try using `tail`; was your guess correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 3: Describe `countries`\n",
    "\n",
    "It's important to understand a few fundamentals about your data before you start work with it, including what information it contains, how large it is, and how the values are generally distributed.\n",
    "\n",
    "Using the methods and attributes above, answer the following questions about `countries`:\n",
    "\n",
    "* what columns does it contain?\n",
    "* what does each row stand for?\n",
    "* how many rows and columns does it contain?\n",
    "* are there any missing values in the latitude or longitude columns? \n",
    "\n",
    "Hint: the `head` and `describe` functions, as well as the `shape` attribute, will be helpful here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What columns does it contain?\n",
    "\n",
    "**Answer**: Use the `.columns` data attribute of the `countries` `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countries.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What does each row stand for?\n",
    "\n",
    "**Answer**: Each row stands for a single country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How many rows and columns does it contain?\n",
    "\n",
    "**Answer**: Use the `.shape` data attribute to return a `tuple` containing the (# of rows, # of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countries.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Are there any missing values in the latitude or longitude columns?\n",
    "\n",
    "**Answer**: Using the `describe` method, we see that the count for both latitude and longitude are `30.0`, which is the number of rows, so there is no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 4: Renaming a Column\n",
    "\n",
    "The \"other_feature\" column in our `bacteria` table isn't very descriptive. Suppose we know that \"other_feature\" refers to a second set of bacteria count observations. Use the `rename` method to give \"other_feature\" a more descriptive name.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bacteria dataframe\n",
    "bacteria = pd.DataFrame(\n",
    "    {'bacteria_counts' : [632, 1638, 569, 115],\n",
    "    'other_feature' : [438, 833, 234, 298]},\n",
    "    index=['Firmicutes',\n",
    "           'Proteobacteria',\n",
    "           'Actinobacteria',\n",
    "           'Bacteroidetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"other_feature\" in bacteria\n",
    "bacteria.rename(columns={'other_feature': 'second_count'}, inplace=True)\n",
    "bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 5: Indexing to Obtain a Specific Value\n",
    "\n",
    "Both `loc` and `iloc` can be used to select a particular value if they are given two arguments. The first argument is the name (when using `loc`) or index number (when using `iloc`) of the *row* you want, while the second argument is the name or index number of the *column* you want.\n",
    "\n",
    "Using `loc`, select \"Bacteroidetes\" and \"bacteria_counts\" to get the count of Bacteroidetes.\n",
    "\n",
    "BONUS: how could you do the same task using `iloc`?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria.loc['Bacteroidetes', 'bacteria_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria.iloc[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria[3:4]['bacteria_counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 6: Indexing Multiple Rows and Columns\n",
    "\n",
    "Both `loc` and `iloc` can be used to select subsets of columns *and* rows at the same time if they are given lists (and/or slices, for `iloc`] as their two arguments. \n",
    "\n",
    "Using `iloc` on the `unemployment` DataFrame, get:\n",
    "* every row starting at row 4 and ending at row 7\n",
    "* the 0th, 2nd, and 3rd columns\n",
    "\n",
    "BONUS: how could you do the same task using `loc`?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.rename(columns={'month' : 'year_month'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.iloc[3:7, [0, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.loc[3:7, ['country', 'year_month', 'unemployment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh-oh, those are different! Why? Because using slices in `.loc` treats the end position in the slice inclusively, while slicing with `.iloc` (and on the dataframe itself!) treats the end position in the slice exclusively (as Python lists and `numpy` does).\n",
    "\n",
    "So, we need to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.loc[3:6, ['country', 'year_month', 'unemployment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 7: Another Way to Obtain the Year\n",
    "\n",
    "If you didn't know that casting floats to ints truncates the decimals in Python, you could have used NumPy's `floor()` function. `np.floor` takes an array or `pd.Series` of floats as its argument, and returns an array or `pd.Series` where every float has been rounded down to the nearest whole number. \n",
    "\n",
    "Use `np.floor` to round the values in the `year_month` column down so we can cast them as integer years. Note that the types are still floats, so we'll still need to use `astype` to typecast.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['year'] = unemployment['year_month'].astype(int)\n",
    "unemployment['month'] = ((unemployment['year_month'] - unemployment['year']) * 100).round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = unemployment[['country',\n",
    "                             'seasonality',\n",
    "                             'year_month',\n",
    "                             'year',\n",
    "                             'month',\n",
    "                             'unemployment',\n",
    "                             'unemployment_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the \"year_month\" column\n",
    "year_month = unemployment.loc[:, 'year_month']\n",
    "year_month = unemployment['year_month']\n",
    "\n",
    "# Use np.floor on year_month to get the years as floats\n",
    "years_by_floor = np.floor(year_month)\n",
    "\n",
    "# Cast years_by_floor to integers using astype(int)\n",
    "int_years = years_by_floor.astype(int)\n",
    "\n",
    "# Check that this gets the same answers as our first approach\n",
    "# This should return True\n",
    "(unemployment['year_month'].astype(int) == int_years).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line of code in the previous cell does an element-wise comparison of the values in the corresponding arrays. The `.all()` method checks whether *all* elements are `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 8\n",
    "\n",
    "You may sometimes need to merge on columns with different names. To do so, use the `left_on` and `right_on` parameters, where the first listed `DataFrame` is the \"left\" one and the second is the \"right.\" It might look something this:\n",
    "\n",
    "```\n",
    "pd.merge(one, two, left_on='city', right_on='city_name')\n",
    "```\n",
    "\n",
    "Suppose wanted to merge `unemployment` with a new DataFrame called `country_codes`, where the abbreviation for each country is in the column \"c_code\":\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_url = 'https://raw.githubusercontent.com/dlab-berkeley/Python-Data-Wrangling/main/data/countries.csv'\n",
    "countries = pd.read_csv(countries_url)\n",
    "country_names = countries[['country', 'country_group', 'name_en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.merge(unemployment, country_names, on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = country_names.rename({\"country\": \"c_code\"}, axis=1).drop(\"country_group\", axis=1)\n",
    "country_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `merge` to merge `unemployment` and `country_codes` on their country codes. Make sure to specify `left_on=` and `right_on=` in the call to `merge`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged = pd.merge(unemployment, country_codes, left_on='country', right_on='c_code')\n",
    "unemployment_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 9: Exploring Unemployment Rates\n",
    "\n",
    "What are the minimum and maximum unemployment rates in our data set? Which unemployment rates are most and least common?\n",
    "\n",
    "Hint: look at where we found the minimum and maximum years for a hint to the first question, and use `value_counts` for the second.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['unemployment_rate'].min(), unemployment['unemployment_rate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['unemployment_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['unemployment_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 10: Group By Practice\n",
    "\n",
    "Find the average unemployment rate for European Union vs. non-European Union countries. \n",
    "\n",
    "1. First, use `groupby()` to group on \"country_group\".\n",
    "2. Then, select the \"unemployment_rate\" column,\n",
    "3. Aggregate by using `.mean()` to get the average.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.groupby('country_group')['unemployment_rate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 11: Boolean Indexing\n",
    "\n",
    "Suppose we only want to look at unemployment data from the year 2000 or later. Use Boolean indexing to create a DataFrame with only these years.\n",
    "\n",
    "1. Select the \"year\" column from `unemployment`.\n",
    "2. Using the year data, create a **mask**: an array of Booleans where each value is True if and only if the year is 2000 or later. Remember, you can use Boolean operators like `>`, `<`, and `==` on a column.\n",
    "3. Use the mask from step 2 to index `unemployment`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the year column from unemployment\n",
    "year = unemployment['year']\n",
    "\n",
    "# Create a mask\n",
    "later_or_equal_2000 = year >= 2000\n",
    "\n",
    "# Boolean index unemployment\n",
    "unemployment_2000later = unemployment[later_or_equal_2000]\n",
    "unemployment_2000later.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 12: Plot without Missing Values\n",
    "\n",
    "Note that there are some dates for which we lack data on Spain's unemployment rate. What could you do if you wanted your plot to show only dates where both Spain and Portugal have a defined unemployment rate?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.dropna(subset=['unemployment_rate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.sort_values(['name_en', 'year_month'], inplace=True)\n",
    "unemployment.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = unemployment[(unemployment['name_en'].isin(['Portugal', 'Spain'])) &\n",
    "                  (unemployment['seasonality'] == 'sa')]\n",
    "datetimes = pd.to_datetime(ps['year'].astype(str) + '/' + ps['month'].astype(str) + '/1')\n",
    "ps.insert(loc=0, column='date', value=datetimes)\n",
    "ps = ps[['date', 'name_en', 'unemployment_rate']]\n",
    "ps.columns = ['Time Period', 'Country', 'Unemployment Rate']\n",
    "ps = ps.pivot(index='Time Period', columns='Country', values='Unemployment Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_nomissing = ps.dropna()\n",
    "ps_nomissing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_nomissing.plot(figsize=(10, 8), title='Unemployment Rate\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6f9fe9f4b7182690503d8ecc2bae97b0ee3ebf54e877167ae4d28c119a56988"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
